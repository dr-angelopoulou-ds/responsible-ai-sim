# Responsible AI in Learning & Teaching ‚Äî Interactive Simulator

üîó **Live demo:**  
https://dr-angelopoulou-ds.github.io/responsible-ai-sim/index.html

---

## Overview

This project is a **self-guided, interactive Responsible AI learning module** designed for **students and faculty**.  
It visualizes **ethical trade-offs** in common educational AI use cases‚Äîwithout requiring technical or machine learning background.

The simulator helps users explore how decisions around automation, transparency, verification, accessibility, and privacy affect:

- Learning quality
- Fairness and inclusion
- Trust
- Ethical risk

The tool is intentionally designed to be:
- **Facilitator-free**
- **Embeddable in Google Sites or LMS platforms**
- **Accessible and plain-language**
- **Reusable as an Open Educational Resource (OER)**

---

## What This Is (and Is Not)

### ‚úÖ What it is
- A **teaching simulator** for Responsible AI literacy
- A **decision-focused visualization** (not technical ML internals)
- A **discussion and reflection tool** for students and faculty
- A **deploy-once, low-maintenance** web resource

### ‚ùå What it is not
- A real machine learning model
- A grading or assessment tool
- A detector of AI use or misconduct
- A risk scoring system for individuals

All scores and charts are **illustrative** and exist solely to make ethical trade-offs visible.

---

## Intended Audience

- **Students** using AI for learning, assignments, or studying
- **Faculty** using AI for feedback, grading support, or course materials
- **Educational developers, librarians, and administrators**
- **Workshops, orientations, or self-paced AI literacy modules**

No coding or AI expertise is required.

---

## Key Features

### Interactive Controls
Users adjust decisions such as:
- Automation level
- Human verification & review
- Transparency & disclosure
- Accessibility & inclusive design
- Decision stakes (grades/opportunities)
- Data sensitivity (privacy risk)
- Hallucination likelihood (error risk)

### Visual Outputs
The simulator dynamically updates:
- Trade-off chart (learning, trust, fairness, accessibility, efficiency)
- Risk indicators (bias, privacy, reliability)
- Differential impact view (illustrative group outcomes)
- Overall ethical risk indicator (low / medium / high)

### Reflection Prompts
Built-in prompts support:
- Student self-reflection
- Faculty policy discussions
- Responsible AI conversations without facilitation

---

## Site Structure

- `index.html` ‚Äî Interactive Responsible AI simulator
- `students.html` ‚Äî Student-facing AI use guidance
- `faculty.html` ‚Äî Faculty responsibilities and safeguards
- `templates.html` ‚Äî Copy/paste policy and transparency templates

All pages are static HTML and require **no backend**.

---

## Accessibility & Design Principles

This project follows Responsible AI best practices by design:

- Plain-language explanations (no ML jargon)
- Color is never the only meaning carrier
- Mobile-responsive layout
- Clear disclaimers and transparency
- Human-centered labels (learning, trust, fairness‚Äînot accuracy/F1)

---

## Deployment & Hosting

This site is hosted using **GitHub Pages** and can be embedded into:

- Google Sites
- Canvas / LMS pages
- Department or library websites

### To embed in Google Sites
1. Copy the live URL
2. Google Sites ‚Üí Insert ‚Üí Embed ‚Üí URL
3. Resize the embed container as needed

---

## Educational Use & Licensing

This project is suitable for:
- AI literacy modules
- Faculty development
- Student orientations
- Responsible AI workshops
- Grant broader impacts deliverables

You are encouraged to:
- Reuse
- Remix
- Adapt language for your institution

---

## Disclaimer

This simulator is a **conceptual teaching tool**.  
All outputs are illustrative and **do not measure real-world risk or performance**.

Human judgment, institutional policy, and ethical responsibility always take precedence.

---

## Contact / Attribution

Created as an educational Responsible AI resource.

If you reuse or adapt this project, attribution is appreciated.
